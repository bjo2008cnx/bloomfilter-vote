package com.ximalaya.bloomfilterext.bloom;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.concurrent.atomic.AtomicLong;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Adjusted Counting Bloom Filter Algorithm
 * Thread safe
 * @author will
 * @see <code>CountingBloomFilter</code>
 */
public final class AdjustedCountingBloomFilter extends NIOFilter {
	
	 /** Storage for the counting buckets */
	  private AtomicLong[] buckets;

	  /** We are using 4bit buckets, so each bucket can count to 15 */
	  private final static long BUCKET_MAX_VALUE = 15;
	  
	  /** Max update retry times */
	  private final static long MAX_UPDATE_RETRY_TIMES = 6;
	  
	  private static final Logger LOG = LoggerFactory.getLogger(AdjustedCountingBloomFilter.class);
	  
	  /** Default constructor - use with readFields */
	  public AdjustedCountingBloomFilter() {}
	  
	  /**
	   * Constructor
	   * @param vectorSize The vector size of <i>this</i> filter.
	   * @param nbHash The number of hash function to consider.
	   * @param hashType type of the hashing function (see
	   * {@link org.apache.hadoop.util.hash.Hash}).
	   */
	  public AdjustedCountingBloomFilter(int vectorSize, int nbHash, int hashType) {
	    super(vectorSize, nbHash, hashType);
	    int bucketSize = buckets2words(vectorSize);
	    buckets = new AtomicLong[bucketSize];
	    for(int i = 0; i < bucketSize; i++) {
	    	buckets[i] = new AtomicLong(0);   // initial value is set to 0
	    }
	  }

	  /** returns the number of 64 bit words it would take to hold vectorSize buckets */
	  private static int buckets2words(int vectorSize) {
	   return ((vectorSize - 1) >>> 4) + 1;
	  }


	  @Override
	  public void add(Key key) {
	    if(key == null) {
	      throw new NullPointerException("key can not be null");
	    }

	    int[] h = hash.hash(key);
	    hash.clear();

	    for(int i = 0; i < nbHash; i++) {
	      // find the bucket
	      int wordNum = h[i] >> 4;          // div 16
	      int bucketShift = (h[i] & 0x0f) << 2;  // (mod 16) * 4
	      
	      long bucketMask = 15L << bucketShift;
	      
	      boolean hasUpdatedSuccess = false;   // 是否更新成功
	      int retriedTimes = 0;   // 已重试次数
	      while(!hasUpdatedSuccess && retriedTimes < MAX_UPDATE_RETRY_TIMES) {
	    	  long oldVal = buckets[wordNum].get();
		      long bucketValue = (oldVal & bucketMask) >>> bucketShift;
		      
		      // only increment if the count in the bucket is less than BUCKET_MAX_VALUE
		      if(bucketValue < BUCKET_MAX_VALUE) {
		        // increment by 1
		        hasUpdatedSuccess = buckets[wordNum]
		        						.compareAndSet(oldVal, 
		        									   (oldVal & ~bucketMask) | ((bucketValue + 1) << bucketShift));
		      }
		      
		      retriedTimes++;
	      }
	      
	      // do log
	      if(!hasUpdatedSuccess && retriedTimes == MAX_UPDATE_RETRY_TIMES) {
	    	  LOG.error("collision occurn: add");
	      }
	    }
	  }

	  /**
	   * Removes a specified key from <i>this</i> counting Bloom filter.
	   * <p>
	   * <b>Invariant</b>: nothing happens if the specified key does not belong to <i>this</i> counter Bloom filter.
	   * @param key The key to remove.
	   */
	  public void delete(Key key) {
	    if(key == null) {
	      throw new NullPointerException("Key may not be null");
	    }
	    if(!membershipTest(key)) {
	      throw new IllegalArgumentException("Key is not a member");
	    }

	    int[] h = hash.hash(key);
	    hash.clear();

	    for(int i = 0; i < nbHash; i++) {
	      // find the bucket
	      int wordNum = h[i] >> 4;          // div 16
	      int bucketShift = (h[i] & 0x0f) << 2;  // (mod 16) * 4
	      
	      long bucketMask = 15L << bucketShift;
	      
	      boolean hasUpdatedSuccess = false;   // 是否更新成功
	      int retriedTimes = 0;   // 已重试次数
	      while(!hasUpdatedSuccess && retriedTimes < MAX_UPDATE_RETRY_TIMES) {
	    	  long oldVal = buckets[wordNum].get();
		      long bucketValue = (oldVal & bucketMask) >>> bucketShift;
		      // only decrement if the count in the bucket is between 0 and BUCKET_MAX_VALUE
		      if(bucketValue >= 1 && bucketValue < BUCKET_MAX_VALUE) {
		        // decrement by 1
		        hasUpdatedSuccess = buckets[wordNum]
		        						.compareAndSet(oldVal, 
		        									   (oldVal & ~bucketMask) | ((bucketValue - 1) << bucketShift));
		      }
		      
		      retriedTimes++;
	      }   // while ends
	      
	      // do log
	      if(!hasUpdatedSuccess && retriedTimes == MAX_UPDATE_RETRY_TIMES) {
	    	  LOG.error("collision occurn: delete");
	      }
	    }
	  }

	  @Override
	  public void and(NIOFilter filter) {
	    if(filter == null
	        || !(filter instanceof AdjustedCountingBloomFilter)
	        || filter.vectorSize != this.vectorSize
	        || filter.nbHash != this.nbHash) {
	      throw new IllegalArgumentException("filters cannot be and-ed");
	    }
	    AdjustedCountingBloomFilter cbf = (AdjustedCountingBloomFilter) filter;
	    
	    int sizeInWords = buckets2words(vectorSize);
	    for(int i = 0; i < sizeInWords; i++) {
	    	boolean hasUpdatedSuccess = false;   // 是否更新成功
	    	int retriedTimes = 0;   // 已重试次数
	    	while(!hasUpdatedSuccess && retriedTimes < MAX_UPDATE_RETRY_TIMES) {
	    		long oldVal = buckets[i].get();
	    		hasUpdatedSuccess = buckets[i].compareAndSet(oldVal, oldVal & cbf.buckets[i].get());
	    	  
	    		retriedTimes++;
	    	}   // while ends
	    	
		    // do log
		    if(!hasUpdatedSuccess && retriedTimes == MAX_UPDATE_RETRY_TIMES) {
		        LOG.error("collision occurn: and");
		    }
	    }
	  }

	  @Override
	  public boolean membershipTest(Key key) {
	    if(key == null) {
	      throw new NullPointerException("Key may not be null");
	    }

	    int[] h = hash.hash(key);
	    hash.clear();

	    for(int i = 0; i < nbHash; i++) {
	      // find the bucket
	      int wordNum = h[i] >> 4;          // div 16
	      int bucketShift = (h[i] & 0x0f) << 2;  // (mod 16) * 4

	      long bucketMask = 15L << bucketShift;

	      if((buckets[wordNum].get() & bucketMask) == 0) {
	        return false;
	      }
	    }

	    return true;
	  }

	  /**
	   * This method calculates an approximate count of the key, i.e. how many
	   * times the key was added to the filter. This allows the filter to be
	   * used as an approximate <code>key -&gt; count</code> map.
	   * <p>NOTE: due to the bucket size of this filter, inserting the same
	   * key more than 15 times will cause an overflow at all filter positions
	   * associated with this key, and it will significantly increase the error
	   * rate for this and other keys. For this reason the filter can only be
	   * used to store small count values <code>0 &lt;= N &lt;&lt; 15</code>.
	   * @param key key to be tested
	   * @return 0 if the key is not present. Otherwise, a positive value v will
	   * be returned such that <code>v == count</code> with probability equal to the
	   * error rate of this filter, and <code>v &gt; count</code> otherwise.
	   * Additionally, if the filter experienced an underflow as a result of
	   * {@link #delete(Key)} operation, the return value may be lower than the
	   * <code>count</code> with the probability of the false negative rate of such
	   * filter.
	   */
	  public int approximateCount(Key key) {
	    int res = Integer.MAX_VALUE;
	    int[] h = hash.hash(key);
	    hash.clear();
	    for (int i = 0; i < nbHash; i++) {
	      // find the bucket
	      int wordNum = h[i] >> 4;          // div 16
	      int bucketShift = (h[i] & 0x0f) << 2;  // (mod 16) * 4
	      
	      long bucketMask = 15L << bucketShift;
	      long bucketValue = (buckets[wordNum].get() & bucketMask) >>> bucketShift;
	      if (bucketValue < res) 
	    	  res = (int)bucketValue;
	    }
	    
	    if (res != Integer.MAX_VALUE) {
	      return res;
	    } else {
	      return 0;
	    }
	  }

	  @Override
	  public void not() {
	    throw new UnsupportedOperationException("not() is undefined for "
	        + this.getClass().getName());
	  }

	  @Override
	  public void or(NIOFilter filter) {
	    if(filter == null
	        || !(filter instanceof NIOFilter)
	        || filter.vectorSize != this.vectorSize
	        || filter.nbHash != this.nbHash) {
	      throw new IllegalArgumentException("filters cannot be or-ed");
	    }

	    AdjustedCountingBloomFilter cbf = (AdjustedCountingBloomFilter)filter;

	    int sizeInWords = buckets2words(vectorSize);
	    for(int i = 0; i < sizeInWords; i++) {
	    	boolean hasUpdatedSuccess = false;   // 是否更新成功
	    	int retriedTimes = 0;   // 已重试次数
	    	while(!hasUpdatedSuccess && retriedTimes < MAX_UPDATE_RETRY_TIMES) {
	    		long oldVal = buckets[i].get();
	    		hasUpdatedSuccess = buckets[i].compareAndSet(oldVal, oldVal | cbf.buckets[i].get());
	    		
	    		retriedTimes++;
	    	}   // while ends
	    	
		    // do log
		    if(!hasUpdatedSuccess && retriedTimes == MAX_UPDATE_RETRY_TIMES) {
		    	LOG.error("collision occurn: or");
		    }
	    }
	  }

	  @Override
	  public void xor(NIOFilter filter) {
	    throw new UnsupportedOperationException("xor() is undefined for "
	        + this.getClass().getName());
	  }

	  @Override
	  public String toString() {
	    StringBuilder res = new StringBuilder();

	    for(int i = 0; i < vectorSize; i++) {
	      if(i > 0) {
	        res.append(" ");
	      }
	      
	      int wordNum = i >> 4;          // div 16
	      int bucketShift = (i & 0x0f) << 2;  // (mod 16) * 4
	      
	      long bucketMask = 15L << bucketShift;
	      long bucketValue = (buckets[wordNum].get() & bucketMask) >>> bucketShift;
	      
	      res.append(bucketValue);
	    }

	    return res.toString();
	  }

	  // Writable

	  @Override
	  public void write(ByteBuffer out) throws IOException {
	    super.write(out);
	    int sizeInWords = buckets2words(vectorSize);
	    for(int i = 0; i < sizeInWords; i++) {
	      out.putLong(buckets[i].get());
	    }
	  }

	  @Override
	  public void readFields(ByteBuffer in) throws IOException {
	    super.readFields(in);
	    int sizeInWords = buckets2words(vectorSize);
	    buckets = new AtomicLong[sizeInWords];
	    for(int i = 0; i < sizeInWords; i++) {
	    	buckets[i] = new AtomicLong(in.getLong());
	    }
	  }
	  
	  public int getVectorSize() {
		  return this.vectorSize;
	  }
	  
	  public int getNbHash() {
		  return this.nbHash;
	  }
	  
	  public int getHashType() {
		  return this.hashType;
	  }
	
}
